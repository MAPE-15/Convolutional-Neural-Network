{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "fe1368e4c8a47c02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T20:57:19.994194Z",
     "start_time": "2024-09-27T20:57:18.281659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "from PIL import Image"
   ],
   "id": "db3498eb397da313",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Constants",
   "id": "dfcf95a14f20c9f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T20:57:19.998937Z",
     "start_time": "2024-09-27T20:57:19.997144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_DIR = os.path.join(os.getcwd(), \"data\")\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")"
   ],
   "id": "9f7fcc1d59d4d11e",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convolutional Neural Network",
   "id": "7edbbe1dbb3989b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reading Data\n",
    "Data are images 48x48 in grayscale (expected size is 48x48, but grayscale is mandatory for the images).  \n",
    "Grayscale meaning, there is only 1 channel (for RGB image there are 3 channels).  \n",
    "So the actual image is of size (48, 48, 1) - (image_width, image_height, n_channels).  \n",
    "\n",
    "This section extracts the images and labels.\n",
    "\n",
    "1. Read images, from each image remember its label (f.e. happy, sad, ...). We now have images and label_names lists.\n",
    "2. Map the label names list, each label name will now have its own identificator. (f.e. happy = 0, sad = 1, ...). We now have labels list.\n",
    "3. Convert the labels list into a 2D one-hot encoded vector array."
   ],
   "id": "c08143d6f64ad20f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T20:57:20.008413Z",
     "start_time": "2024-09-27T20:57:20.005609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_data(data_dir: str, image_size=(48, 48)) -> (np.array, np.array):\n",
    "    \n",
    "    \"\"\"\n",
    "    Reading data from data_dir.\n",
    "    Each image is processed, converted into a numpy array and then normalized (every value is divided by 255).\n",
    "    Image is expected to be in grayscale (.convert('L')), and its size should be 48x48 (default).\n",
    "    \n",
    "    Expected directory tree from which the images are processed:\n",
    "    - data_dir\n",
    "        - facial_expression_dir1\n",
    "            - image1\n",
    "            - image2\n",
    "            - ...\n",
    "        - facial_expression_dir2 \n",
    "        - facial_expression_dir3\n",
    "        - ...\n",
    "        - facial_expression_dirN\n",
    "        \n",
    "    :param data_dir: directory from which the images are processed\n",
    "    :param image_size: size of the images, default is 48x48\n",
    "    :return: two numpy arrays, first numpy array has stored all the images, and second numpy array has stored all the label names\n",
    "    \"\"\"\n",
    "    \n",
    "    images = []\n",
    "    label_names = []\n",
    "    \n",
    "    for expression_dirname in sorted(os.listdir(data_dir)):  \n",
    "        # get every directory, this directory contains images of facial expressions \n",
    "        \n",
    "        expression_dir = os.path.join(data_dir, expression_dirname)\n",
    "        \n",
    "        if not os.path.isdir(expression_dir):  # process only directories, skip non-directories - files\n",
    "            continue\n",
    "            \n",
    "        for expression_image in os.listdir(expression_dir):\n",
    "            # get every image in the directory\n",
    "            \n",
    "            image_path = os.path.join(expression_dir, expression_image)\n",
    "            \n",
    "            try:\n",
    "                image = Image.open(image_path).convert('L')  # L mode, because images are grayscaled\n",
    "                image = image.resize(image_size)  # resize the image to expected 48x48\n",
    "                \n",
    "                # convert image into an array, image is a 2D array\n",
    "                image_array = np.array(image)\n",
    "                \n",
    "                # normalize image values, values between 0 - 1\n",
    "                image_array = image_array / 255.0\n",
    "\n",
    "                images.append(image_array)\n",
    "                label_names.append(expression_dirname)  # directory name is already a label name of a facial expression\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process image: {image_path}\")\n",
    "                print(e)\n",
    "    \n",
    "    # convert images and labels list into numpy arrays adn return them\n",
    "    return np.array(images), np.array(label_names)            "
   ],
   "id": "625c2057213acb0d",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T20:57:26.654972Z",
     "start_time": "2024-09-27T20:57:20.015248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_images, train_label_names = get_data(TRAIN_DIR)\n",
    "test_images, test_label_names = get_data(TEST_DIR)\n",
    "\n",
    "print(\"Train Images:\")\n",
    "print(train_images.shape)\n",
    "print(train_images, '\\n')\n",
    "\n",
    "print(\"Test Images:\")\n",
    "print(test_images.shape)\n",
    "print(test_images, '\\n')\n",
    "\n",
    "print(\"Train Labels:\")\n",
    "print(train_label_names.shape)\n",
    "print(train_label_names, '\\n')\n",
    "\n",
    "print(\"Test Labels:\")\n",
    "print(test_label_names.shape)\n",
    "print(test_label_names, '\\n')"
   ],
   "id": "39db644581ce34dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images:\n",
      "(28709, 48, 48)\n",
      "[[[0.70980392 0.70196078 0.69411765 ... 0.71372549 0.71372549 0.71372549]\n",
      "  [0.70196078 0.69803922 0.69019608 ... 0.70196078 0.69411765 0.68627451]\n",
      "  [0.70196078 0.69803922 0.69019608 ... 0.67843137 0.70196078 0.7254902 ]\n",
      "  ...\n",
      "  [0.76862745 0.70980392 0.74901961 ... 0.90196078 0.89411765 0.80392157]\n",
      "  [0.76078431 0.72941176 0.78431373 ... 0.89019608 0.87058824 0.91372549]\n",
      "  [0.77647059 0.77254902 0.83137255 ... 0.88627451 0.85882353 0.95294118]]\n",
      "\n",
      " [[0.08235294 0.07058824 0.10588235 ... 0.32941176 0.20392157 0.24705882]\n",
      "  [0.08235294 0.08235294 0.10980392 ... 0.34509804 0.28235294 0.36078431]\n",
      "  [0.09019608 0.10980392 0.12941176 ... 0.4        0.41176471 0.45882353]\n",
      "  ...\n",
      "  [0.99607843 0.99215686 1.         ... 0.63921569 0.61960784 0.61176471]\n",
      "  [1.         1.         1.         ... 0.59607843 0.64705882 0.59607843]\n",
      "  [0.99607843 1.         0.99215686 ... 0.61568627 0.57647059 0.56078431]]\n",
      "\n",
      " [[0.16078431 0.24705882 0.33333333 ... 0.13333333 0.1372549  0.1254902 ]\n",
      "  [0.14117647 0.21960784 0.30196078 ... 0.1254902  0.10980392 0.13333333]\n",
      "  [0.12941176 0.19607843 0.3254902  ... 0.15686275 0.09019608 0.12941176]\n",
      "  ...\n",
      "  [0.51764706 0.5372549  0.52941176 ... 0.33333333 0.29411765 0.32156863]\n",
      "  [0.49411765 0.54117647 0.58039216 ... 0.35294118 0.31764706 0.30588235]\n",
      "  [0.48627451 0.54509804 0.59607843 ... 0.37647059 0.33333333 0.31764706]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.98431373 0.98431373 0.97254902 ... 0.97254902 0.98431373 0.98039216]\n",
      "  [0.98431373 0.98431373 0.99607843 ... 0.98039216 0.98039216 0.98431373]\n",
      "  [0.98039216 0.98039216 0.98431373 ... 0.97254902 0.97647059 0.96862745]\n",
      "  ...\n",
      "  [0.98823529 0.97254902 0.98431373 ... 0.92941176 0.91764706 0.9254902 ]\n",
      "  [0.98039216 0.98431373 0.98431373 ... 0.92941176 0.92941176 0.94117647]\n",
      "  [0.99215686 0.98431373 0.98431373 ... 0.9372549  0.94117647 0.94509804]]\n",
      "\n",
      " [[0.99215686 0.99215686 1.         ... 0.99215686 0.99215686 1.        ]\n",
      "  [0.99215686 0.99607843 0.98823529 ... 0.99607843 0.99215686 0.99607843]\n",
      "  [1.         1.         1.         ... 0.99607843 0.99215686 1.        ]\n",
      "  ...\n",
      "  [0.09411765 0.08627451 0.07843137 ... 0.13333333 0.14901961 0.13333333]\n",
      "  [0.09411765 0.05882353 0.09019608 ... 0.14509804 0.1372549  0.14509804]\n",
      "  [0.09803922 0.08235294 0.05882353 ... 0.14509804 0.13333333 0.14509804]]\n",
      "\n",
      " [[0.96862745 0.99215686 0.99607843 ... 0.02745098 0.03529412 0.03529412]\n",
      "  [0.98039216 0.69803922 0.64705882 ... 0.05882353 0.03921569 0.07058824]\n",
      "  [0.83529412 0.62352941 0.9254902  ... 0.09019608 0.02745098 0.05490196]\n",
      "  ...\n",
      "  [0.99215686 1.         1.         ... 0.25098039 0.34901961 0.40784314]\n",
      "  [0.99215686 0.91764706 0.85098039 ... 0.23921569 0.36470588 0.44705882]\n",
      "  [0.61568627 0.56470588 0.5254902  ... 0.25098039 0.44313725 0.57254902]]] \n",
      "\n",
      "Test Images:\n",
      "(7178, 48, 48)\n",
      "[[[0.3254902  0.29411765 0.24313725 ... 0.12156863 0.12156863 0.12156863]\n",
      "  [0.23921569 0.20784314 0.20784314 ... 0.12156863 0.12156863 0.1254902 ]\n",
      "  [0.16862745 0.14901961 0.13333333 ... 0.14117647 0.11764706 0.10588235]\n",
      "  ...\n",
      "  [0.08235294 0.07843137 0.07843137 ... 0.03921569 0.04313725 0.0627451 ]\n",
      "  [0.09411765 0.08627451 0.07843137 ... 0.06666667 0.04313725 0.02745098]\n",
      "  [0.08627451 0.08235294 0.05882353 ... 0.04705882 0.03529412 0.03921569]]\n",
      "\n",
      " [[0.49803922 0.49411765 0.48235294 ... 0.24313725 0.24705882 0.19607843]\n",
      "  [0.50588235 0.49803922 0.49019608 ... 0.23921569 0.25490196 0.21960784]\n",
      "  [0.51372549 0.50196078 0.49803922 ... 0.23529412 0.21960784 0.22352941]\n",
      "  ...\n",
      "  [0.80784314 0.77254902 0.81176471 ... 0.06666667 0.05490196 0.11372549]\n",
      "  [0.78823529 0.76862745 0.87058824 ... 0.12941176 0.05490196 0.10196078]\n",
      "  [0.74901961 0.80392157 0.9372549  ... 0.50196078 0.38039216 0.30588235]]\n",
      "\n",
      " [[0.98039216 0.98431373 0.98431373 ... 0.98039216 0.98039216 0.97647059]\n",
      "  [0.98039216 0.98431373 0.98039216 ... 0.96078431 0.98431373 0.98431373]\n",
      "  [0.97647059 0.98431373 0.98039216 ... 1.         0.96078431 0.97647059]\n",
      "  ...\n",
      "  [0.59215686 0.58823529 0.60784314 ... 0.25882353 0.41960784 0.37254902]\n",
      "  [0.58823529 0.59607843 0.62352941 ... 0.34901961 0.41960784 0.3372549 ]\n",
      "  [0.6        0.6        0.61960784 ... 0.42352941 0.38431373 0.33333333]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.03921569 0.21568627 0.23921569 ... 0.23137255 0.02745098 0.00784314]\n",
      "  [0.20784314 0.25490196 0.2627451  ... 0.25098039 0.10980392 0.        ]\n",
      "  [0.25490196 0.25882353 0.2745098  ... 0.27058824 0.22352941 0.00784314]\n",
      "  ...\n",
      "  [0.00784314 0.         0.01568627 ... 0.01176471 0.01960784 0.01176471]\n",
      "  [0.01176471 0.01176471 0.         ... 0.00784314 0.01960784 0.00392157]\n",
      "  [0.00392157 0.01568627 0.00784314 ... 0.33333333 0.03137255 0.02745098]]\n",
      "\n",
      " [[0.98431373 0.57254902 0.27843137 ... 0.29411765 0.79215686 0.99607843]\n",
      "  [0.91764706 0.50196078 0.27843137 ... 0.23921569 0.72941176 1.        ]\n",
      "  [0.83921569 0.44705882 0.29803922 ... 0.2627451  0.71764706 0.99607843]\n",
      "  ...\n",
      "  [1.         1.         1.         ... 1.         0.99215686 1.        ]\n",
      "  [1.         1.         1.         ... 1.         0.99607843 1.        ]\n",
      "  [1.         1.         1.         ... 1.         1.         1.        ]]\n",
      "\n",
      " [[0.69411765 0.72156863 0.54901961 ... 0.70588235 0.71372549 0.71764706]\n",
      "  [0.69803922 0.74901961 0.4        ... 0.71764706 0.70588235 0.70980392]\n",
      "  [0.69803922 0.74117647 0.27843137 ... 0.71764706 0.71372549 0.72156863]\n",
      "  ...\n",
      "  [0.4627451  0.80392157 0.8        ... 0.29019608 0.33333333 0.38823529]\n",
      "  [0.36862745 0.77254902 0.81176471 ... 0.43921569 0.39607843 0.35294118]\n",
      "  [0.2        0.61960784 0.89019608 ... 0.26666667 0.40784314 0.42352941]]] \n",
      "\n",
      "Train Labels:\n",
      "(28709,)\n",
      "['angry' 'angry' 'angry' ... 'surprise' 'surprise' 'surprise'] \n",
      "\n",
      "Test Labels:\n",
      "(7178,)\n",
      "['angry' 'angry' 'angry' ... 'surprise' 'surprise' 'surprise'] \n",
      "\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T20:57:26.666113Z",
     "start_time": "2024-09-27T20:57:26.664353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Example of one Image:\")\n",
    "print(train_images[0].shape)\n",
    "print(train_images[0])"
   ],
   "id": "f885cc333320f6f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of one Image:\n",
      "(48, 48)\n",
      "[[0.70980392 0.70196078 0.69411765 ... 0.71372549 0.71372549 0.71372549]\n",
      " [0.70196078 0.69803922 0.69019608 ... 0.70196078 0.69411765 0.68627451]\n",
      " [0.70196078 0.69803922 0.69019608 ... 0.67843137 0.70196078 0.7254902 ]\n",
      " ...\n",
      " [0.76862745 0.70980392 0.74901961 ... 0.90196078 0.89411765 0.80392157]\n",
      " [0.76078431 0.72941176 0.78431373 ... 0.89019608 0.87058824 0.91372549]\n",
      " [0.77647059 0.77254902 0.83137255 ... 0.88627451 0.85882353 0.95294118]]\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Map the label names into actual labels\n",
    "Each label name should have its integer identificator.  \n",
    "From label names list get labels list, where label name has been replaced by its identificator"
   ],
   "id": "e11ed3988dafd9e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T20:57:26.682589Z",
     "start_time": "2024-09-27T20:57:26.680862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def map_label_names(label_names: np.array) -> np.array:\n",
    "    \n",
    "    \"\"\"\n",
    "    Map the label names, each label name will have its own identificator.\n",
    "    Replace the label names with their unique identifier.\n",
    "    :param label_names: list of label names\n",
    "    :return: an array of labels, where now the label names have been replaced by their unique identifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    mapped_labels = {}\n",
    "    \n",
    "    # map the unique label names\n",
    "    for label, unique_label_name in enumerate(np.unique(label_names)):\n",
    "        mapped_labels[unique_label_name] = label\n",
    "\n",
    "    # replace label name by its identificator\n",
    "    labels = np.array([mapped_labels[label_name] for label_name in label_names])\n",
    "    \n",
    "    return labels"
   ],
   "id": "877316d53a12fe4e",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T20:57:26.700185Z",
     "start_time": "2024-09-27T20:57:26.691527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_labels = map_label_names(train_label_names)\n",
    "test_labels = map_label_names(test_label_names)\n",
    "\n",
    "print(\"Train labels:\")\n",
    "print(train_labels.shape)\n",
    "print(train_labels, '\\n')\n",
    "\n",
    "print(\"Test labels:\")\n",
    "print(test_labels.shape)\n",
    "print(test_labels)"
   ],
   "id": "8fedd15c8f86ad28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels:\n",
      "(28709,)\n",
      "[0 0 0 ... 6 6 6] \n",
      "\n",
      "Test labels:\n",
      "(7178,)\n",
      "[0 0 0 ... 6 6 6]\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Encode the labels into one hot vectors\n",
   "id": "c5e254108e6ab149"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T20:57:26.707732Z",
     "start_time": "2024-09-27T20:57:26.705947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def one_hot_encode(labels: np.array, num_classes: int):\n",
    "    \n",
    "    \"\"\"\n",
    "    Encode the labels 1D vector into one-hot vectors encoding.\n",
    "    One hot encoded vector has all zeros, but only one 1.\n",
    "    \n",
    "    :param labels: 1D vector of labels \n",
    "        F.e.:\n",
    "        happy: 0\n",
    "        sad: 1\n",
    "        angry: 2\n",
    "        labels: [0, 0, 1, 1, 2]\n",
    "        \n",
    "    :param num_classes: number of unique classes - of unique labels (f.e. 3 - happy, sad, and angry)\n",
    "    :return: a 2D one hot encoded array.\n",
    "    \n",
    "            F.e.:\n",
    "            labels = [0, 0, 1, 1, 2]\n",
    "            one_hot = \n",
    "                [\n",
    "                    [1 0 0]\n",
    "                    [1 0 0]\n",
    "                    [0 1 0]\n",
    "                    [0 1 0]\n",
    "                    [0 0 1]\n",
    "                ]\n",
    "            - shape of one_hot: (n_labels, unique_labels)\n",
    "    \"\"\"\n",
    "    \n",
    "    # an array full of zeros of shape (num_labels, num_classes) \n",
    "    one_hot = np.zeros((len(labels), num_classes))\n",
    "    \n",
    "    # set the 1 to appropriate labels\n",
    "    for n_row, label in enumerate(labels):\n",
    "        one_hot[n_row, label] = 1\n",
    "    \n",
    "    return one_hot"
   ],
   "id": "457f69a8205cc79c",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T20:57:26.724533Z",
     "start_time": "2024-09-27T20:57:26.718387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_classes = len(np.unique(test_labels))\n",
    "\n",
    "train_labels_one_hot = one_hot_encode(train_labels, num_classes)\n",
    "test_labels_one_hot = one_hot_encode(test_labels, num_classes)\n",
    "\n",
    "print(\"Train labels one-hot:\")\n",
    "print(train_labels_one_hot.shape)\n",
    "print(train_labels_one_hot, '\\n')\n",
    "\n",
    "print(\"Test labels one-hot:\")\n",
    "print(test_labels_one_hot.shape)\n",
    "print(test_labels_one_hot, '\\n')"
   ],
   "id": "17ea33015821beae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels one-hot:\n",
      "(28709, 7)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]] \n",
      "\n",
      "Test labels one-hot:\n",
      "(7178, 7)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]] \n",
      "\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Final Representation of Data\n",
    "\n",
    "\n",
    "Training and testing sets:  \n",
    "- image arrays: train_images and test_images\n",
    "- one-hot encoded vector arrays: train_labels_one_hot, test_labels_one_hot"
   ],
   "id": "7453b4f228769d08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T20:57:26.739936Z",
     "start_time": "2024-09-27T20:57:26.737093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train Images (first 5):\")\n",
    "print(train_images.shape)\n",
    "print(train_images[:5], '\\n')\n",
    "\n",
    "print(\"Test Images (first 5):\")\n",
    "print(test_images.shape)\n",
    "print(test_images[:5], '\\n')\n",
    "\n",
    "print(\"Train Labels one-hot:\")\n",
    "print(train_labels_one_hot.shape)\n",
    "print(train_labels_one_hot, '\\n')\n",
    "\n",
    "print(\"Test Labels one-hot:\")\n",
    "print(test_labels_one_hot.shape)\n",
    "print(test_labels_one_hot, '\\n')"
   ],
   "id": "3e494c38a77f17dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images (first 5):\n",
      "(28709, 48, 48)\n",
      "[[[0.70980392 0.70196078 0.69411765 ... 0.71372549 0.71372549 0.71372549]\n",
      "  [0.70196078 0.69803922 0.69019608 ... 0.70196078 0.69411765 0.68627451]\n",
      "  [0.70196078 0.69803922 0.69019608 ... 0.67843137 0.70196078 0.7254902 ]\n",
      "  ...\n",
      "  [0.76862745 0.70980392 0.74901961 ... 0.90196078 0.89411765 0.80392157]\n",
      "  [0.76078431 0.72941176 0.78431373 ... 0.89019608 0.87058824 0.91372549]\n",
      "  [0.77647059 0.77254902 0.83137255 ... 0.88627451 0.85882353 0.95294118]]\n",
      "\n",
      " [[0.08235294 0.07058824 0.10588235 ... 0.32941176 0.20392157 0.24705882]\n",
      "  [0.08235294 0.08235294 0.10980392 ... 0.34509804 0.28235294 0.36078431]\n",
      "  [0.09019608 0.10980392 0.12941176 ... 0.4        0.41176471 0.45882353]\n",
      "  ...\n",
      "  [0.99607843 0.99215686 1.         ... 0.63921569 0.61960784 0.61176471]\n",
      "  [1.         1.         1.         ... 0.59607843 0.64705882 0.59607843]\n",
      "  [0.99607843 1.         0.99215686 ... 0.61568627 0.57647059 0.56078431]]\n",
      "\n",
      " [[0.16078431 0.24705882 0.33333333 ... 0.13333333 0.1372549  0.1254902 ]\n",
      "  [0.14117647 0.21960784 0.30196078 ... 0.1254902  0.10980392 0.13333333]\n",
      "  [0.12941176 0.19607843 0.3254902  ... 0.15686275 0.09019608 0.12941176]\n",
      "  ...\n",
      "  [0.51764706 0.5372549  0.52941176 ... 0.33333333 0.29411765 0.32156863]\n",
      "  [0.49411765 0.54117647 0.58039216 ... 0.35294118 0.31764706 0.30588235]\n",
      "  [0.48627451 0.54509804 0.59607843 ... 0.37647059 0.33333333 0.31764706]]\n",
      "\n",
      " [[0.19607843 0.2        0.2        ... 0.38039216 0.4627451  0.46666667]\n",
      "  [0.20392157 0.20392157 0.2        ... 0.32156863 0.47058824 0.47843137]\n",
      "  [0.20392157 0.19215686 0.2        ... 0.30980392 0.44313725 0.47843137]\n",
      "  ...\n",
      "  [0.09411765 0.09803922 0.19607843 ... 0.25098039 0.24705882 0.22745098]\n",
      "  [0.09411765 0.10196078 0.15686275 ... 0.23921569 0.24313725 0.21960784]\n",
      "  [0.12156863 0.11764706 0.15294118 ... 0.23529412 0.22352941 0.22745098]]\n",
      "\n",
      " [[0.16078431 0.1372549  0.10980392 ... 0.         0.00392157 0.        ]\n",
      "  [0.16470588 0.14509804 0.09019608 ... 0.         0.00392157 0.00392157]\n",
      "  [0.16470588 0.12156863 0.11372549 ... 0.         0.         0.00784314]\n",
      "  ...\n",
      "  [0.18823529 0.2        0.21568627 ... 0.23529412 0.21176471 0.21568627]\n",
      "  [0.24313725 0.22352941 0.23137255 ... 0.24313725 0.2        0.21568627]\n",
      "  [0.34901961 0.25098039 0.27843137 ... 0.23529412 0.20784314 0.21176471]]] \n",
      "\n",
      "Test Images (first 5):\n",
      "(7178, 48, 48)\n",
      "[[[0.3254902  0.29411765 0.24313725 ... 0.12156863 0.12156863 0.12156863]\n",
      "  [0.23921569 0.20784314 0.20784314 ... 0.12156863 0.12156863 0.1254902 ]\n",
      "  [0.16862745 0.14901961 0.13333333 ... 0.14117647 0.11764706 0.10588235]\n",
      "  ...\n",
      "  [0.08235294 0.07843137 0.07843137 ... 0.03921569 0.04313725 0.0627451 ]\n",
      "  [0.09411765 0.08627451 0.07843137 ... 0.06666667 0.04313725 0.02745098]\n",
      "  [0.08627451 0.08235294 0.05882353 ... 0.04705882 0.03529412 0.03921569]]\n",
      "\n",
      " [[0.49803922 0.49411765 0.48235294 ... 0.24313725 0.24705882 0.19607843]\n",
      "  [0.50588235 0.49803922 0.49019608 ... 0.23921569 0.25490196 0.21960784]\n",
      "  [0.51372549 0.50196078 0.49803922 ... 0.23529412 0.21960784 0.22352941]\n",
      "  ...\n",
      "  [0.80784314 0.77254902 0.81176471 ... 0.06666667 0.05490196 0.11372549]\n",
      "  [0.78823529 0.76862745 0.87058824 ... 0.12941176 0.05490196 0.10196078]\n",
      "  [0.74901961 0.80392157 0.9372549  ... 0.50196078 0.38039216 0.30588235]]\n",
      "\n",
      " [[0.98039216 0.98431373 0.98431373 ... 0.98039216 0.98039216 0.97647059]\n",
      "  [0.98039216 0.98431373 0.98039216 ... 0.96078431 0.98431373 0.98431373]\n",
      "  [0.97647059 0.98431373 0.98039216 ... 1.         0.96078431 0.97647059]\n",
      "  ...\n",
      "  [0.59215686 0.58823529 0.60784314 ... 0.25882353 0.41960784 0.37254902]\n",
      "  [0.58823529 0.59607843 0.62352941 ... 0.34901961 0.41960784 0.3372549 ]\n",
      "  [0.6        0.6        0.61960784 ... 0.42352941 0.38431373 0.33333333]]\n",
      "\n",
      " [[0.36862745 0.71764706 0.79215686 ... 0.01176471 0.00392157 0.01568627]\n",
      "  [0.61568627 0.75294118 0.79607843 ... 0.         0.01176471 0.00784314]\n",
      "  [0.70588235 0.77647059 0.81176471 ... 0.         0.01568627 0.01568627]\n",
      "  ...\n",
      "  [0.01176471 0.         0.         ... 0.02352941 0.04313725 0.0627451 ]\n",
      "  [0.         0.         0.00784314 ... 0.03529412 0.04313725 0.06666667]\n",
      "  [0.         0.01176471 0.01176471 ... 0.04705882 0.05490196 0.09411765]]\n",
      "\n",
      " [[0.28627451 0.30588235 0.3372549  ... 0.57647059 0.60784314 0.61960784]\n",
      "  [0.2745098  0.34117647 0.37647059 ... 0.56862745 0.60392157 0.61568627]\n",
      "  [0.34509804 0.35294118 0.42352941 ... 0.55686275 0.59607843 0.61176471]\n",
      "  ...\n",
      "  [0.27058824 0.25098039 0.24705882 ... 0.33333333 0.31764706 0.29803922]\n",
      "  [0.27058824 0.25882353 0.25882353 ... 0.3254902  0.31372549 0.29019608]\n",
      "  [0.27058824 0.2627451  0.25098039 ... 0.31764706 0.30980392 0.29019608]]] \n",
      "\n",
      "Train Labels one-hot:\n",
      "(28709, 7)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]] \n",
      "\n",
      "Test Labels one-hot:\n",
      "(7178, 7)\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]] \n",
      "\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Helpful Functions\n",
    "Functions that have nothing to do with CNN.  \n",
    "Helpful functions to make the program run smoothly."
   ],
   "id": "917b70cd4bffacdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bd60adc58b052c7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Convolutional Layers",
   "id": "722a9283be8dba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Custom Errors\n",
    "Made custom errors, which can be raised in the convolutional layer."
   ],
   "id": "15f83df2028defab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T20:57:26.766417Z",
     "start_time": "2024-09-27T20:57:26.764223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class InvalidNumberOfFilters(Exception):\n",
    "    \"\"\" Invalid number of filters specified \"\"\"\n",
    "    def __init__(self, message=\"Invalid number of filters specified by the user\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "\n",
    "\n",
    "class InvalidFilterSize(Exception):\n",
    "    \"\"\" Invalid filter size specified \"\"\"\n",
    "    def __init__(self, message=\"Invalid filter size specified by the user\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "        \n",
    "        \n",
    "class InvalidNumberOfChannels(Exception):\n",
    "    \"\"\" Invalid number of channels specified \"\"\"\n",
    "    def __init__(self, message=\"Invalid number of channels specified by the user\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "        \n",
    "        \n",
    "class InvalidPadding(Exception):\n",
    "    \"\"\" Invalid padding specified \"\"\"\n",
    "    def __init__(self, message=\"Invalid padding specified by the user\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)\n",
    "        \n",
    "\n",
    "class InvalidStride(Exception):\n",
    "    \"\"\" Invalid stride specified \"\"\"\n",
    "    def __init__(self, message=\"Invalid stride specified by the user\"):\n",
    "        self.message = message\n",
    "        super().__init__(self.message)"
   ],
   "id": "7a273879b5674dcd",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T21:14:04.951196Z",
     "start_time": "2024-09-27T21:14:04.940108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConvLayer:\n",
    "    \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_filters: int, filter_size: int, num_channels: int):\n",
    "        \"\"\"\n",
    "        Function constructor, initialize the filter array.\n",
    "        \n",
    "        :param num_filters: number of filters in the convolutional layer\n",
    "        :param filter_size: size of the filter, num_channels x filter_size x filter_size\n",
    "        :param num_channels: depth of the filter - kernel\n",
    "        :raises \n",
    "        \"\"\"\n",
    "        \n",
    "        if not isinstance(num_filters, int):\n",
    "            raise ValueError(\"Number of filters \\\"num_filters\\\" must be an integer!\")\n",
    "        elif num_filters < 1:\n",
    "            raise InvalidNumberOfFilters(f\"Number of filters \\\"num_filters\\\" must be at least 1, \\\"num_filters={num_filters}\\\" specified instead!\")\n",
    "        \n",
    "        if not isinstance(filter_size, int):\n",
    "            raise ValueError(\"Filter - kernel size \\\"filter_size\\\" must be an integer!\")\n",
    "        elif filter_size < 2:\n",
    "            raise InvalidFilterSize(f\"Filter - kernel size \\\"filter_size\\\" must be at least 2, \\\"filter_size={filter_size}\\\" specified instead!\")\n",
    "            \n",
    "        if not isinstance(num_channels, int):\n",
    "            raise ValueError(\"Number of channels \\\"num_channels\\\" must be an integer!\")\n",
    "        elif num_channels < 1:\n",
    "            raise InvalidNumberOfChannels(f\"Number of channels \\\"num_channels\\\" must be at least 1, \\\"num_channels={num_channels}\\\" was specified instead!\")\n",
    "            \n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.num_channels = num_channels\n",
    "        \n",
    "        # creates a 4D numpy array\n",
    "        # filter is of size (c x f x f), where f is the filter_size, and c is the num_channels\n",
    "        # (c x f x f) because image size is expected to be (c x height x width)\n",
    "        self.filters = np.random.randn(num_filters, num_channels, filter_size, filter_size) / filter_size ** 2\n",
    "    \n",
    "    \n",
    "    def shift_filter_window(self, image: np.array, stride: int) -> (np.array, int, int):\n",
    "        \n",
    "        \"\"\"\n",
    "        Shift the filter window to get all the regions in the image.\n",
    "        These regions are for the convolutional operations with the kernel - filter.\n",
    "        \n",
    "        :param image: image from which to get all the regions from.\n",
    "        :param stride: size of the stride, shift size - how big a step/shift\n",
    "        :return: a region (where input image and kernel intersect) which is a 2D array, and (i, j) coordinates of the region  \n",
    "        \"\"\"\n",
    "        \n",
    "        _, height, width = image.shape\n",
    "        \n",
    "        # shift the filter window, to process all regions in the input image\n",
    "        for i in range(0, height - self.filter_size + 1, stride):\n",
    "            for j in range(0, width - self.filter_size + 1, stride):\n",
    "                # extract the region of the image where the filter is applied\n",
    "                region = image[:, i: (i + self.filter_size), j: (j + self.filter_size)]\n",
    "                yield region, i, j  # what yield does that it returns a value, but this function has to be interated to get next() values\n",
    "                \n",
    "                \n",
    "    def forward(self, image: np.array, stride: int = 1, padding: int = 0):\n",
    "\n",
    "        \"\"\"\n",
    "        Perform forward pass through the convolutional layer.\n",
    "        Perform convolutional operations with the kernel - filter \n",
    "        \n",
    "        :param image: image to perform convolutional operation on \n",
    "        :param padding: padding applied to the image\n",
    "        :param stride: stride applied to the convolutional operation\n",
    "        :return: \n",
    "        \"\"\"\n",
    "        \n",
    "        if not isinstance(stride, int):\n",
    "            raise ValueError(\"Stride must be an integer!\")\n",
    "        elif stride < 1:\n",
    "            raise InvalidStride(f\"Stride must be at least 1, \\\"stride={stride}\\\" specified instead!\")\n",
    "        \n",
    "        if not isinstance(padding, int):\n",
    "            raise ValueError(\"Padding must be an integer!\")\n",
    "        elif padding < 0:\n",
    "            raise InvalidPadding(f\"Padding must be at least 0, \\\"padding={padding}\\\" specified instead!\")\n",
    "        \n",
    "        # if image is 2D (single channel, number of channels is 1), expand from (height x width) into (1 x height x width) so it has a depth=1\n",
    "        if image.ndim == 2:\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "        padded_image = self.pad_image(image, padding)  # apply padding to the image\n",
    "        _, height, width = image.shape  # get only height and width, image is of size (n_channels x height x width)\n",
    "        \n",
    "        # expected output height and width\n",
    "        output_height = (height + 2 * padding - self.filter_size) // stride + 1\n",
    "        output_width = (width + 2 * padding - self.filter_size) // stride + 1\n",
    "        \n",
    "        output = np.zeros((self.num_filters, output_height, output_width))\n",
    "\n",
    "        for region, i, j in self.shift_filter_window(padded_image, stride):\n",
    "            for n_filter in range(self.num_filters):\n",
    "                # perform convolution on the region using the filter\n",
    "                output[n_filter, i // stride, j // stride] = self.conv(region, self.filters[n_filter]) \n",
    "        \n",
    "        return output\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def conv(image_region: np.array, kernel: np.array) -> np.array:\n",
    "        \n",
    "        \"\"\"\n",
    "        Perform convolutional operation on the image region using the filter.\n",
    "        Convolution operation is sum(image_region * filter)\n",
    "        \n",
    "        :param image_region: region to perform convolutional operation on\n",
    "        :param kernel: filter - kernel to perform convolutional operation with\n",
    "        :return: convolution result\n",
    "        \"\"\"\n",
    "        \n",
    "        result = 0\n",
    "  \n",
    "        # perform convolution for each channel separately and sum the result\n",
    "        for channel in range(image_region.shape[0]):  # loop over the channels\n",
    "            conv_result = convolve2d(image_region[channel], kernel[channel], mode=\"valid\")\n",
    "            result += conv_result.item()  # extract the scalar value if it is a 1 x 1 array\n",
    "\n",
    "        return result\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def pad_image(image: np.array, padding: int) -> np.array:\n",
    "        \n",
    "        \"\"\"\n",
    "        Apply zero-padding to the input image with multiple channels.\n",
    "        \n",
    "        :param image: image to apply padding on\n",
    "        :param padding: padding applied to the image\n",
    "        :return: padded image\n",
    "        \"\"\"\n",
    "        \n",
    "        if padding > 0:\n",
    "            # apply padding to the height and width dimensions (1 and 2), keeping channels dimension intact\n",
    "            padded_image = np.pad(image, ((0, 0), (padding, padding), (padding, padding)), mode=\"constant\")\n",
    "        else:\n",
    "            padded_image = image\n",
    "            \n",
    "        return padded_image\n",
    "        "
   ],
   "id": "7e0f8dfc5486b5e2",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T21:28:16.945074Z",
     "start_time": "2024-09-27T21:23:49.873237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example of using one convolutional layer, using only forward pass\n",
    "\n",
    "conv_layer1 = ConvLayer(num_filters=3, filter_size=4, num_channels=1)\n",
    "\n",
    "batch_size = 300\n",
    "convolved_images = []\n",
    "\n",
    "for i in range(0, train_images.shape[0], batch_size):  # loop over all the number of images (28709)\n",
    "    \n",
    "    print(f\"{(i // batch_size) + 1}. batch {i}/{train_images.shape[0]}\")\n",
    "    \n",
    "    convolved_batch = []\n",
    "    batch_images = train_images[i: i + batch_size]  # Get the i-th image (shape 48x48)\n",
    "    \n",
    "    for image in batch_images:\n",
    "        convolved_image = conv_layer1.forward(image, padding=0, stride=1)\n",
    "        convolved_batch.append(convolved_image)\n",
    "    \n",
    "    convolved_images.extend(np.array(convolved_batch))\n",
    "\n",
    "convolved_images = np.array(convolved_images)"
   ],
   "id": "ef5198811a4a8416",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. batch 0/28709\n",
      "2. batch 300/28709\n",
      "3. batch 600/28709\n",
      "4. batch 900/28709\n",
      "5. batch 1200/28709\n",
      "6. batch 1500/28709\n",
      "7. batch 1800/28709\n",
      "8. batch 2100/28709\n",
      "9. batch 2400/28709\n",
      "10. batch 2700/28709\n",
      "11. batch 3000/28709\n",
      "12. batch 3300/28709\n",
      "13. batch 3600/28709\n",
      "14. batch 3900/28709\n",
      "15. batch 4200/28709\n",
      "16. batch 4500/28709\n",
      "17. batch 4800/28709\n",
      "18. batch 5100/28709\n",
      "19. batch 5400/28709\n",
      "20. batch 5700/28709\n",
      "21. batch 6000/28709\n",
      "22. batch 6300/28709\n",
      "23. batch 6600/28709\n",
      "24. batch 6900/28709\n",
      "25. batch 7200/28709\n",
      "26. batch 7500/28709\n",
      "27. batch 7800/28709\n",
      "28. batch 8100/28709\n",
      "29. batch 8400/28709\n",
      "30. batch 8700/28709\n",
      "31. batch 9000/28709\n",
      "32. batch 9300/28709\n",
      "33. batch 9600/28709\n",
      "34. batch 9900/28709\n",
      "35. batch 10200/28709\n",
      "36. batch 10500/28709\n",
      "37. batch 10800/28709\n",
      "38. batch 11100/28709\n",
      "39. batch 11400/28709\n",
      "40. batch 11700/28709\n",
      "41. batch 12000/28709\n",
      "42. batch 12300/28709\n",
      "43. batch 12600/28709\n",
      "44. batch 12900/28709\n",
      "45. batch 13200/28709\n",
      "46. batch 13500/28709\n",
      "47. batch 13800/28709\n",
      "48. batch 14100/28709\n",
      "49. batch 14400/28709\n",
      "50. batch 14700/28709\n",
      "51. batch 15000/28709\n",
      "52. batch 15300/28709\n",
      "53. batch 15600/28709\n",
      "54. batch 15900/28709\n",
      "55. batch 16200/28709\n",
      "56. batch 16500/28709\n",
      "57. batch 16800/28709\n",
      "58. batch 17100/28709\n",
      "59. batch 17400/28709\n",
      "60. batch 17700/28709\n",
      "61. batch 18000/28709\n",
      "62. batch 18300/28709\n",
      "63. batch 18600/28709\n",
      "64. batch 18900/28709\n",
      "65. batch 19200/28709\n",
      "66. batch 19500/28709\n",
      "67. batch 19800/28709\n",
      "68. batch 20100/28709\n",
      "69. batch 20400/28709\n",
      "70. batch 20700/28709\n",
      "71. batch 21000/28709\n",
      "72. batch 21300/28709\n",
      "73. batch 21600/28709\n",
      "74. batch 21900/28709\n",
      "75. batch 22200/28709\n",
      "76. batch 22500/28709\n",
      "77. batch 22800/28709\n",
      "78. batch 23100/28709\n",
      "79. batch 23400/28709\n",
      "80. batch 23700/28709\n",
      "81. batch 24000/28709\n",
      "82. batch 24300/28709\n",
      "83. batch 24600/28709\n",
      "84. batch 24900/28709\n",
      "85. batch 25200/28709\n",
      "86. batch 25500/28709\n",
      "87. batch 25800/28709\n",
      "88. batch 26100/28709\n",
      "89. batch 26400/28709\n",
      "90. batch 26700/28709\n",
      "91. batch 27000/28709\n",
      "92. batch 27300/28709\n",
      "93. batch 27600/28709\n",
      "94. batch 27900/28709\n",
      "95. batch 28200/28709\n",
      "96. batch 28500/28709\n"
     ]
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T21:28:16.953829Z",
     "start_time": "2024-09-27T21:28:16.951223Z"
    }
   },
   "cell_type": "code",
   "source": "convolved_images.shape",
   "id": "cce03ea6e23eeaeb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 3, 45, 45)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c5b28d6583bc3714"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
